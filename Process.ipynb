{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL_ASSIGNMENT\n",
    "===============\n",
    "\n",
    "Eugene & Maaike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Finding Data\n",
    "=================\n",
    "\n",
    "chosing a datset: \n",
    "We started with the dataset '120 years of Olympic history: athletes and results' which is a CSV file available at Kaggle.com. We The second dataset holds weatherdata from OpenWeatherMap for the dates of each of the Olympic Games.    \n",
    " \n",
    "Project proposal: \n",
    "Goal of the project is to make tables to analyze in what way the weather found on weatherdata influences the medal count.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Data cleanup in CSV\n",
    "====================\n",
    "Reducing the dataset:\n",
    "\n",
    "\n",
    "The dataset olympic history included data of the last 120 years of summer and winter olympics. \n",
    "We decided to focus on the years 1984 (the year the olympics were held in Los Angeles) until 2014 (last year of available data).\n",
    "\n",
    "\n",
    "Included in the dataset were the height and weight of the atlethes, but there are a lot of missing values and we decided not to use this information and took in put of the CSV file\n",
    "\n",
    "\n",
    "We replaced all the NaN values at the medal column for an empty line to make the data load\n",
    "\n",
    "\n",
    "The data we will use in the project are :\n",
    "-  id of athlete: int\n",
    "-  name (first and lastname): varchar\n",
    "-  sex (male, female): varchar\n",
    "-  age (whole number): int\n",
    "-  team (country athlete plays for): varchar\n",
    "-  year (the year of the games): int\n",
    "-  season (winter or summer games): varchar\n",
    "-  city (in which the games are held): varchar\n",
    "-  sport (type of sport, f.e. iceskating): varchar\n",
    "-  event (f.e. 5000 m men iceskating): varchar\n",
    "-  medal (none/empty, bronze, silver, gold): varchar\n",
    "\n",
    "We imported the raw data from dataset olympic history dataset. \n",
    "\n",
    "code:\n",
    " - create table raw_data (id int, name varchar(100), sex varchar(10), age int, team varchar(100), year int, season varchar(100), city varchar(100), sport varchar(100), event varchar(200), medal varchar(100));\n",
    "\n",
    "\n",
    " - load data local infile 'c:\\\\games.csv' into table raw_data fields terminated by ',' enclosed by '\"' lines terminated by '\\n' (Id, name, sex, age, team, year, season, city, sport, event, medal);\n",
    " \n",
    " For the weather data, we created an API to call data from OpenWeatherMap historical data.  The API called http://history.openweathermap.org/data/2.5/history/city?id={id}&type=hour&start={start}&end={end} and returned the following data:\n",
    "\n",
    "- City\n",
    "- Date\n",
    "- Average High Temperature (for day)\n",
    "- Average Precipitation (for day)\n",
    "\n",
    "When the data was returned, we used Pandas to convert the data to CSV format which was then loaded into a separate MySQL \"Weather\" table.  We also used PAndas to check for data inconsistancies which we found none.  We did however need to import a time function in order to convert the 'Date\" data from unix time in UTC to PST in the CSV.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Data cleanup in MySql\n",
    "=================\n",
    "\n",
    "After importing the data in MySql we create all the normalized tables we need for the analysis:\n",
    "\n",
    " - games\n",
    "create table games (games_id mediumint not null auto_increment, year int, city_name varchar(100), primary key(games_id));\n",
    "  \n",
    "  \n",
    " - sports\n",
    "create table sports (sports_id mediumint not null auto_increment, sports_name varchar(100), primary key(sports_id));\n",
    "  \n",
    "  \n",
    " - events\n",
    "create table events (events_id mediumint not null auto_increment, events_name varchar(100), primary key(events_id));\n",
    "  \n",
    "  \n",
    " - teams\n",
    "create table teams (teams_id mediumint not null auto_increment, teams_name varchar(100), primary key(teams_id));\n",
    "  \n",
    "  \n",
    " - athletes\n",
    "create table athletes (athletes_id mediumint not null auto_increment, athletes_name varchar(100), athletes_sex varchar(100), athletes_age int, primary key (athletes_id));\n",
    "  \n",
    "  \n",
    " - medals\n",
    "create table medals (medals_id mediumint not null auto_increment, medal_name varchar(100), games_id int, sports_id int, events_id int, teams_id int, athletes_id int, primary key(medals_id));\n",
    "\n",
    "- weather\n",
    "create table weather (weather_id medium int not null auto_increment, city varchar(50), date date, avg_temp smallint, avg_precip smallint\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Transformation and normalization of the data\n",
    "=================\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleanup & Analysis\n",
    "Once you have identified your datasets, perform ETL on the data. Make sure to plan and document the following:\n",
    "\n",
    "\n",
    "The sources of data that you will extract from.\n",
    "\n",
    "\n",
    "The type of transformation needed for this data (cleaning, joining, filtering, aggregating, etc).\n",
    "\n",
    "\n",
    "The type of final production database to load the data into (relational or non-relational).\n",
    "\n",
    "\n",
    "The final tables or collections that will be used in the production database.\n",
    "\n",
    "\n",
    "You will be required to submit a final technical report with the above information and steps required to reproduce your ETL process.\n",
    "\n",
    "Project Report\n",
    "At the end of the week, your team will submit a Final Report that describes the following:\n",
    "\n",
    "\n",
    "Extract: your original data sources and how the data was formatted (CSV, JSON, MySQL, etc).\n",
    "\n",
    "\n",
    "Transform: what data cleaning or transformation was required.\n",
    "\n",
    "\n",
    "Load: the final database, tables/collections, and why this was chosen.\n",
    "\n",
    "\n",
    "Please upload the report to Github and submit a link to Bootcampspot.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
